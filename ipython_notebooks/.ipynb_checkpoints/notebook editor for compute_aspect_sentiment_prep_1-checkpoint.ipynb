{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import dataiku\n",
    "import pandas as pd, numpy as np\n",
    "from dataiku import pandasutils as pdu\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from aspect_clustering.vector_dist import vector_dist\n",
    "from run_extraction.init_spacy import init_spacy\n",
    "# from aspect_clustering.add_clusters_to_reviews import add_clusters_to_reviews\n",
    "from sklearn import cluster\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read recipe inputs\n",
    "aspect_sentiment_pairs = dataiku.Dataset(\"tweepy_aspect_sentiment_pairs\")\n",
    "df = aspect_sentiment_pairs.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <button style=\"display:none\" \n",
       "            class=\"btn btn-default ipython-export-btn\" \n",
       "            id=\"btn-df-b6c19cf3-e9da-4746-b61e-a08d4ff2e074\" \n",
       "            onclick=\"_export_df('b6c19cf3-e9da-4746-b61e-a08d4ff2e074')\">\n",
       "                Export dataframe\n",
       "            </button>\n",
       "            \n",
       "            <script>\n",
       "                \n",
       "                function _check_export_df_possible(dfid,yes_fn,no_fn) {\n",
       "                    console.log('Checking dataframe exportability...')\n",
       "                    if(!IPython || !IPython.notebook || !IPython.notebook.kernel || !IPython.notebook.kernel) {\n",
       "                        console.log('Export is not possible (IPython kernel is not available)')\n",
       "                        if(no_fn) {\n",
       "                            no_fn();\n",
       "                        }\n",
       "                    } else {\n",
       "                        var pythonCode = 'from dataiku.notebook.export import IPythonExporter;IPythonExporter._check_export_stdout(\"'+dfid+'\")';\n",
       "                        IPython.notebook.kernel.execute(pythonCode,{iopub: {output: function(resp) {\n",
       "                            console.info(\"Exportability response\", resp);\n",
       "                            var size = /^([0-9]+)x([0-9]+)$/.exec(resp.content.data || resp.content.text)\n",
       "                            if(!size) {\n",
       "                                console.log('Export is not possible (dataframe is not in-memory anymore)')\n",
       "                                if(no_fn) {\n",
       "                                    no_fn();\n",
       "                                }\n",
       "                            } else {\n",
       "                                console.log('Export is possible')\n",
       "                                if(yes_fn) {\n",
       "                                    yes_fn(1*size[1],1*size[2]);\n",
       "                                }\n",
       "                            }\n",
       "                        }}});\n",
       "                    }\n",
       "                }\n",
       "            \n",
       "                function _export_df(dfid) {\n",
       "                    \n",
       "                    var btn = $('#btn-df-'+dfid);\n",
       "                    var btns = $('.ipython-export-btn');\n",
       "                    \n",
       "                    _check_export_df_possible(dfid,function() {\n",
       "                        \n",
       "                        window.parent.openExportModalFromIPython('Pandas dataframe',function(data) {\n",
       "                            btns.prop('disabled',true);\n",
       "                            btn.text('Exporting...');\n",
       "                            var command = 'from dataiku.notebook.export import IPythonExporter;IPythonExporter._run_export(\"'+dfid+'\",\"'+data.exportId+'\")';\n",
       "                            var callback = {iopub:{output: function(resp) {\n",
       "                                console.info(\"CB resp:\", resp);\n",
       "                                _check_export_df_possible(dfid,function(rows, cols) {\n",
       "                                    $('#btn-df-'+dfid)\n",
       "                                        .css('display','inline-block')\n",
       "                                        .text('Export this dataframe ('+rows+' rows, '+cols+' cols)')\n",
       "                                        .prop('disabled',false);\n",
       "                                },function() {\n",
       "                                    $('#btn-df-'+dfid).css('display','none');\n",
       "                                });\n",
       "                            }}};\n",
       "                            IPython.notebook.kernel.execute(command,callback,{silent:false}); // yes, silent now defaults to true. figures.\n",
       "                        });\n",
       "                    \n",
       "                    }, function(){\n",
       "                            alert('Unable to export : the Dataframe object is not loaded in memory');\n",
       "                            btn.css('display','none');\n",
       "                    });\n",
       "                    \n",
       "                }\n",
       "                \n",
       "                (function(dfid) {\n",
       "                \n",
       "                    var retryCount = 10;\n",
       "                \n",
       "                    function is_valid_websock(s) {\n",
       "                        return s && s.readyState==1;\n",
       "                    }\n",
       "                \n",
       "                    function check_conn() {\n",
       "                        \n",
       "                        if(!IPython || !IPython.notebook) {\n",
       "                            // Don't even try to go further\n",
       "                            return;\n",
       "                        }\n",
       "                        \n",
       "                        // Check if IPython is ready\n",
       "                        console.info(\"Checking conn ...\")\n",
       "                        if(IPython.notebook.kernel\n",
       "                        && IPython.notebook.kernel\n",
       "                        && is_valid_websock(IPython.notebook.kernel.ws)\n",
       "                        ) {\n",
       "                            \n",
       "                            _check_export_df_possible(dfid,function(rows, cols) {\n",
       "                                $('#btn-df-'+dfid).css('display','inline-block');\n",
       "                                $('#btn-df-'+dfid).text('Export this dataframe ('+rows+' rows, '+cols+' cols)');\n",
       "                            });\n",
       "                            \n",
       "                        } else {\n",
       "                            console.info(\"Conditions are not ok\", IPython.notebook.kernel);\n",
       "                            \n",
       "                            // Retry later\n",
       "                            \n",
       "                            if(retryCount>0) {\n",
       "                                setTimeout(check_conn,500);\n",
       "                                retryCount--;\n",
       "                            }\n",
       "                            \n",
       "                        }\n",
       "                    };\n",
       "                    \n",
       "                    setTimeout(check_conn,100);\n",
       "                    \n",
       "                })(\"b6c19cf3-e9da-4746-b61e-a08d4ff2e074\");\n",
       "                \n",
       "            </script>\n",
       "            \n",
       "        <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>noun</th>\n",
       "      <th>adj</th>\n",
       "      <th>rule</th>\n",
       "      <th>polarity_nltk</th>\n",
       "      <th>polarity_textblob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Air France</td>\n",
       "      <td>1257399326906687489</td>\n",
       "      <td>flights</td>\n",
       "      <td>domestic</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air France</td>\n",
       "      <td>1257398007999401990</td>\n",
       "      <td>air france covid19 https t co</td>\n",
       "      <td>covid19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Air France</td>\n",
       "      <td>1257397306170712064</td>\n",
       "      <td>bailout</td>\n",
       "      <td>french</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Air France</td>\n",
       "      <td>1257397306170712064</td>\n",
       "      <td>haul</td>\n",
       "      <td>short</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air France</td>\n",
       "      <td>1257397306170712064</td>\n",
       "      <td>flights</td>\n",
       "      <td>domestic</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id            review_id                           noun       adj  rule  polarity_nltk  polarity_textblob\n",
       "0  Air France  1257399326906687489                        flights  domestic     1            0.0                0.0\n",
       "1  Air France  1257398007999401990  air france covid19 https t co   covid19     1            0.0                0.0\n",
       "2  Air France  1257397306170712064                        bailout    french     1            0.0                0.0\n",
       "3  Air France  1257397306170712064                           haul     short     1            0.0                0.0\n",
       "4  Air France  1257397306170712064                        flights  domestic     1            0.0                0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "df['noun_lemmatized'] = df.noun.str.lower().apply(lemmatizer.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df.groupby([\"product_id\", 'noun_lemmatized']).agg({'product_id':'size',\n",
    "                                                                \"polarity_nltk\":'mean',\n",
    "                                                                \"polarity_textblob\":'mean',\n",
    "                                                                \"review_id\":\"unique\"}).rename(columns={'product_id':'count',\n",
    "                                                                                                             'polarity_nltk':'mean_polarity_nltk',\n",
    "                                                                                                             'polarity_textblob':'mean_polarity_textblob'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <button style=\"display:none\" \n",
       "            class=\"btn btn-default ipython-export-btn\" \n",
       "            id=\"btn-df-d07809dc-3b96-4a5b-a1bf-de6fa8a88635\" \n",
       "            onclick=\"_export_df('d07809dc-3b96-4a5b-a1bf-de6fa8a88635')\">\n",
       "                Export dataframe\n",
       "            </button>\n",
       "            \n",
       "            <script>\n",
       "                \n",
       "                function _check_export_df_possible(dfid,yes_fn,no_fn) {\n",
       "                    console.log('Checking dataframe exportability...')\n",
       "                    if(!IPython || !IPython.notebook || !IPython.notebook.kernel || !IPython.notebook.kernel) {\n",
       "                        console.log('Export is not possible (IPython kernel is not available)')\n",
       "                        if(no_fn) {\n",
       "                            no_fn();\n",
       "                        }\n",
       "                    } else {\n",
       "                        var pythonCode = 'from dataiku.notebook.export import IPythonExporter;IPythonExporter._check_export_stdout(\"'+dfid+'\")';\n",
       "                        IPython.notebook.kernel.execute(pythonCode,{iopub: {output: function(resp) {\n",
       "                            console.info(\"Exportability response\", resp);\n",
       "                            var size = /^([0-9]+)x([0-9]+)$/.exec(resp.content.data || resp.content.text)\n",
       "                            if(!size) {\n",
       "                                console.log('Export is not possible (dataframe is not in-memory anymore)')\n",
       "                                if(no_fn) {\n",
       "                                    no_fn();\n",
       "                                }\n",
       "                            } else {\n",
       "                                console.log('Export is possible')\n",
       "                                if(yes_fn) {\n",
       "                                    yes_fn(1*size[1],1*size[2]);\n",
       "                                }\n",
       "                            }\n",
       "                        }}});\n",
       "                    }\n",
       "                }\n",
       "            \n",
       "                function _export_df(dfid) {\n",
       "                    \n",
       "                    var btn = $('#btn-df-'+dfid);\n",
       "                    var btns = $('.ipython-export-btn');\n",
       "                    \n",
       "                    _check_export_df_possible(dfid,function() {\n",
       "                        \n",
       "                        window.parent.openExportModalFromIPython('Pandas dataframe',function(data) {\n",
       "                            btns.prop('disabled',true);\n",
       "                            btn.text('Exporting...');\n",
       "                            var command = 'from dataiku.notebook.export import IPythonExporter;IPythonExporter._run_export(\"'+dfid+'\",\"'+data.exportId+'\")';\n",
       "                            var callback = {iopub:{output: function(resp) {\n",
       "                                console.info(\"CB resp:\", resp);\n",
       "                                _check_export_df_possible(dfid,function(rows, cols) {\n",
       "                                    $('#btn-df-'+dfid)\n",
       "                                        .css('display','inline-block')\n",
       "                                        .text('Export this dataframe ('+rows+' rows, '+cols+' cols)')\n",
       "                                        .prop('disabled',false);\n",
       "                                },function() {\n",
       "                                    $('#btn-df-'+dfid).css('display','none');\n",
       "                                });\n",
       "                            }}};\n",
       "                            IPython.notebook.kernel.execute(command,callback,{silent:false}); // yes, silent now defaults to true. figures.\n",
       "                        });\n",
       "                    \n",
       "                    }, function(){\n",
       "                            alert('Unable to export : the Dataframe object is not loaded in memory');\n",
       "                            btn.css('display','none');\n",
       "                    });\n",
       "                    \n",
       "                }\n",
       "                \n",
       "                (function(dfid) {\n",
       "                \n",
       "                    var retryCount = 10;\n",
       "                \n",
       "                    function is_valid_websock(s) {\n",
       "                        return s && s.readyState==1;\n",
       "                    }\n",
       "                \n",
       "                    function check_conn() {\n",
       "                        \n",
       "                        if(!IPython || !IPython.notebook) {\n",
       "                            // Don't even try to go further\n",
       "                            return;\n",
       "                        }\n",
       "                        \n",
       "                        // Check if IPython is ready\n",
       "                        console.info(\"Checking conn ...\")\n",
       "                        if(IPython.notebook.kernel\n",
       "                        && IPython.notebook.kernel\n",
       "                        && is_valid_websock(IPython.notebook.kernel.ws)\n",
       "                        ) {\n",
       "                            \n",
       "                            _check_export_df_possible(dfid,function(rows, cols) {\n",
       "                                $('#btn-df-'+dfid).css('display','inline-block');\n",
       "                                $('#btn-df-'+dfid).text('Export this dataframe ('+rows+' rows, '+cols+' cols)');\n",
       "                            });\n",
       "                            \n",
       "                        } else {\n",
       "                            console.info(\"Conditions are not ok\", IPython.notebook.kernel);\n",
       "                            \n",
       "                            // Retry later\n",
       "                            \n",
       "                            if(retryCount>0) {\n",
       "                                setTimeout(check_conn,500);\n",
       "                                retryCount--;\n",
       "                            }\n",
       "                            \n",
       "                        }\n",
       "                    };\n",
       "                    \n",
       "                    setTimeout(check_conn,100);\n",
       "                    \n",
       "                })(\"d07809dc-3b96-4a5b-a1bf-de6fa8a88635\");\n",
       "                \n",
       "            </script>\n",
       "            \n",
       "        <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>noun_lemmatized</th>\n",
       "      <th>count</th>\n",
       "      <th>mean_polarity_nltk</th>\n",
       "      <th>mean_polarity_textblob</th>\n",
       "      <th>review_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Air France</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.1027</td>\n",
       "      <td>-0.291667</td>\n",
       "      <td>[1255255206620811264]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air France</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>[1243137119138144258]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Air France</td>\n",
       "      <td>100k</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[1256202104693284865]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Air France</td>\n",
       "      <td>10th march 2020</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[1243403788305584131]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air France</td>\n",
       "      <td>11th april</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[1243141859163213824]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Air France</td>\n",
       "      <td>1200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[1255058629822119937]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Air France</td>\n",
       "      <td>12m</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[1242981892883918848]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Air France</td>\n",
       "      <td>12th march</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[1243093929328873472]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Air France</td>\n",
       "      <td>12th march travel date 13th</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[1243070888959864832]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Air France</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>[1245304941050298368]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id              noun_lemmatized  count  mean_polarity_nltk  mean_polarity_textblob              review_id\n",
       "0  Air France                            1      1             -0.1027               -0.291667  [1255255206620811264]\n",
       "1  Air France                          100      2              0.5106                0.400000  [1243137119138144258]\n",
       "2  Air France                         100k      1              0.0000                0.000000  [1256202104693284865]\n",
       "3  Air France              10th march 2020      2              0.0000                0.000000  [1243403788305584131]\n",
       "4  Air France                   11th april      2              0.0000                0.000000  [1243141859163213824]\n",
       "5  Air France                         1200      1              0.0000                0.000000  [1255058629822119937]\n",
       "6  Air France                          12m      2              0.0000                0.000000  [1242981892883918848]\n",
       "7  Air France                   12th march      2              0.0000                0.000000  [1243093929328873472]\n",
       "8  Air France  12th march travel date 13th      2              0.0000                0.000000  [1243070888959864832]\n",
       "9  Air France                           14      1              0.0000                0.285714  [1245304941050298368]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are %d nouns extracted\" %(df_grouped.shape[0]))\n",
    "\n",
    "model_path= dataiku.get_custom_variables()['model_path']\n",
    "nlp = init_spacy(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuality_vec = nlp('punctuality').vector\n",
    "food_vec = nlp('food').vector\n",
    "luggage_vec = nlp('luggage').vector\n",
    "staff_vec = nlp('staff').vector\n",
    "\n",
    "companies = df_grouped.product_id.unique()\n",
    "n_clusters = dataiku.get_custom_variables(typed=True)['NUM_CLUSTERS']\n",
    "if type(n_clusters) != int:\n",
    "    n_clusters = ast.literal_eval(n_clusters)\n",
    "df_vectors = pd.DataFrame()\n",
    "\n",
    "df_grouped['k_means_clusters'] = np.nan\n",
    "df_grouped['group'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in companies:\n",
    "    df_sub = df_grouped[df_grouped.product_id == company]\n",
    "    asp_group = []\n",
    "    asp_vectors = []\n",
    "    for aspect in df_sub.noun_lemmatized:\n",
    "        dist_dic = {}\n",
    "        token_vector = nlp(aspect).vector\n",
    "        asp_vectors.append(token_vector)\n",
    "        # df_grouped[df_grouped.noun_lemmatized==aspect, 'noun_vector'] = token_vector\n",
    "        dist_dic['punctuality'] = vector_dist(token_vector, punctuality_vec)\n",
    "        dist_dic['food'] = vector_dist(token_vector, food_vec)\n",
    "        dist_dic['luggage'] = vector_dist(token_vector, luggage_vec)\n",
    "        dist_dic['staff'] = vector_dist(token_vector, staff_vec)\n",
    "        # group = min([dist_punc, dist_food, dist_lugg, dist_staf])\n",
    "        max_key = max(dist_dic, key=dist_dic.get)\n",
    "        asp_group.append(max_key)\n",
    "\n",
    "    df_grouped.loc[df_grouped.product_id == company, \"group\"] = asp_group\n",
    "    df_grouped.loc[df_grouped.noun_lemmatized.str.lower() == df_grouped.product_id.str.lower(), \"group\"] = \"company\"\n",
    "\n",
    "    df_vectors_sub = pd.DataFrame(asp_vectors)\n",
    "    df_vectors_sub['product_id'] = company\n",
    "    df_vectors_sub['noun_lemmatized'] = df_sub['noun_lemmatized'].values\n",
    "    df_vectors_sub['count'] = df_sub['count'].values\n",
    "\n",
    "    # -------------------------------------------------------------------------------- NOTEBOOK-CELL: CODE\n",
    "    # you have to cluster for each company\n",
    "    kmeans = cluster.KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(asp_vectors)\n",
    "    labels = kmeans.labels_\n",
    "    df_grouped.loc[df_grouped.product_id == company, \"k_means_clusters\"] = labels\n",
    "    df_vectors_sub['k_means_clusters'] = labels\n",
    "    df_vectors = pd.concat([df_vectors, df_vectors_sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped['k_means_clusters'] = df_grouped.k_means_clusters.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute recipe outputs from inputs\n",
    "# TODO: Replace this part by your actual code that computes the output, as a Pandas dataframe\n",
    "# NB: DSS also supports other kinds of APIs for reading and writing data. Please see doc.\n",
    "\n",
    "# aspect_sentiment_categorised_df = df_grouped # For this sample code, simply copy input to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write recipe outputs\n",
    "aspect_sentiment_categorised = dataiku.Dataset(\"tweepy_aspect_sentiment_categorised\")\n",
    "aspect_sentiment_categorised.write_with_schema(df_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write recipe outputs\n",
    "word_vectors = dataiku.Dataset(\"tweepy_word_vectors\")\n",
    "word_vectors.write_with_schema(df_vectors)"
   ]
  }
 ],
 "metadata": {
  "associatedRecipe": "compute_aspect_sentiment_prep_1",
  "creator": "admin",
  "customFields": {},
  "kernelspec": {
   "display_name": "Python (env python36)",
   "language": "python",
   "name": "py-dku-venv-python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "tags": [
   "recipe-editor"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
