{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import dataiku\n",
    "import pandas as pd, numpy as np\n",
    "from dataiku import pandasutils as pdu\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from aspect_clustering.vector_dist import vector_dist\n",
    "from run_extraction.init_spacy import init_spacy\n",
    "# from aspect_clustering.add_clusters_to_reviews import add_clusters_to_reviews\n",
    "from sklearn import cluster\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read recipe inputs\n",
    "aspect_sentiment_pairs = dataiku.Dataset(\"aspect_sentiment_pairs\")\n",
    "df = aspect_sentiment_pairs.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "df['noun_lemmatized'] = df.noun.str.lower().apply(lemmatizer.lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df.groupby([\"product_id\", 'noun_lemmatized']).agg({'product_id':'size',\n",
    "                                                                \"polarity_nltk\":'mean',\n",
    "                                                                \"polarity_textblob\":'mean',\n",
    "                                                                \"review_id\":\"unique\"}).rename(columns={'product_id':'count',\n",
    "                                                                                                             'polarity_nltk':'mean_polarity_nltk',\n",
    "                                                                                                             'polarity_textblob':'mean_polarity_textblob'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are %d nouns extracted\" %(df_grouped.shape[0]))\n",
    "\n",
    "model_path= dataiku.get_custom_variables()['model_path']\n",
    "nlp = init_spacy(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuality_vec = nlp('punctuality').vector\n",
    "food_vec = nlp('food').vector\n",
    "luggage_vec = nlp('luggage').vector\n",
    "staff_vec = nlp('staff').vector\n",
    "\n",
    "companies = df_grouped.product_id.unique()\n",
    "n_clusters = dataiku.get_custom_variables(typed=True)['NUM_CLUSTERS']\n",
    "n_clusters = ast.literal_eval(n_clusters)\n",
    "df_vectors = pd.DataFrame()\n",
    "\n",
    "df_grouped['k_means_clusters'] = np.nan\n",
    "df_grouped['group'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in companies:\n",
    "    df_sub = df_grouped[df_grouped.product_id == company]\n",
    "    asp_group = []\n",
    "    asp_vectors = []\n",
    "    for aspect in df_sub.noun_lemmatized:\n",
    "        dist_dic = {}\n",
    "        token_vector = nlp(aspect).vector\n",
    "        asp_vectors.append(token_vector)\n",
    "        # df_grouped[df_grouped.noun_lemmatized==aspect, 'noun_vector'] = token_vector\n",
    "        dist_dic['punctuality'] = vector_dist(token_vector, punctuality_vec)\n",
    "        dist_dic['food'] = vector_dist(token_vector, food_vec)\n",
    "        dist_dic['luggage'] = vector_dist(token_vector, luggage_vec)\n",
    "        dist_dic['staff'] = vector_dist(token_vector, staff_vec)\n",
    "        # group = min([dist_punc, dist_food, dist_lugg, dist_staf])\n",
    "        max_key = max(dist_dic, key=dist_dic.get)\n",
    "        asp_group.append(max_key)\n",
    "\n",
    "    df_grouped.loc[df_grouped.product_id == company, \"group\"] = asp_group\n",
    "    df_grouped.loc[df_grouped.noun_lemmatized.str.lower() == df_grouped.product_id.str.lower(), \"group\"] = \"company\"\n",
    "\n",
    "    df_vectors_sub = pd.DataFrame(asp_vectors)\n",
    "    df_vectors_sub['product_id'] = company\n",
    "    df_vectors_sub['noun_lemmatized'] = df_sub['noun_lemmatized'].values\n",
    "    df_vectors_sub['count'] = df_sub['count'].values\n",
    "\n",
    "    # -------------------------------------------------------------------------------- NOTEBOOK-CELL: CODE\n",
    "    # you have to cluster for each company\n",
    "    kmeans = cluster.KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(asp_vectors)\n",
    "    labels = kmeans.labels_\n",
    "    df_grouped.loc[df_grouped.product_id == company, \"k_means_clusters\"] = labels\n",
    "    df_vectors_sub['k_means_clusters'] = labels\n",
    "    df_vectors = pd.concat([df_vectors, df_vectors_sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped['k_means_clusters'] = df_grouped.k_means_clusters.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute recipe outputs from inputs\n",
    "# TODO: Replace this part by your actual code that computes the output, as a Pandas dataframe\n",
    "# NB: DSS also supports other kinds of APIs for reading and writing data. Please see doc.\n",
    "\n",
    "# aspect_sentiment_categorised_df = df_grouped # For this sample code, simply copy input to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write recipe outputs\n",
    "aspect_sentiment_categorised = dataiku.Dataset(\"aspect_sentiment_categorised\")\n",
    "aspect_sentiment_categorised.write_with_schema(df_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write recipe outputs\n",
    "word_vectors = dataiku.Dataset(\"word_vectors\")\n",
    "word_vectors.write_with_schema(df_vectors)"
   ]
  }
 ],
 "metadata": {
  "associatedRecipe": "compute_aspect_sentiment_prep",
  "creator": "admin",
  "customFields": {},
  "kernelspec": {
   "display_name": "Python (env python36)",
   "language": "python",
   "name": "py-dku-venv-python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "tags": [
   "recipe-editor"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
