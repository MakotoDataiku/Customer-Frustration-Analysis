{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python script for extracting aspects based on dependancy rules\n",
    "#! /usr/bin/env python\n",
    "\n",
    "#import enchant\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import spacy\n",
    "from time import time\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import json\n",
    "import requests\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import gzip\n",
    "import sys\n",
    "import boto3\n",
    "from boto.s3.connection import S3Connection\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = os.getcwd()\n",
    "PARENT = os.path.dirname(BASE_PATH)\n",
    "# CRED_PATH = BASE_PATH + \"/data/credentials.txt\"\n",
    "\n",
    "#USE THIS FOR IMPORTING ANY FUNCTIONS FROM src\n",
    "sys.path.insert(0,BASE_PATH)\n",
    "from src.dataprep import clean_data\n",
    "\n",
    "prod_pronouns = ['it','this','they','these']\n",
    "\n",
    "def fetch_reviews(filepath,usecols = None):\n",
    "    raw_data = pd.read_table(filepath,nrows=300,error_bad_lines=False,usecols=usecols) #nrows = 300\n",
    "    return raw_data\n",
    "\n",
    "def fetch_s3(filename,usecols = None):\n",
    "    s3_basepath = 's3://amazon-reviews-pds/tsv/'\n",
    "    s3_fullpath = s3_basepath + filename\n",
    "    raw_data = pd.read_table(s3_fullpath, compression = 'gzip',error_bad_lines=False,chunksize=100000,usecols=usecols)\n",
    "    return raw_data\n",
    "\n",
    "\n",
    "def apply_extraction(row,nlp,sid):\n",
    "    review_body = row['review_body']\n",
    "    review_id = row['review_id']\n",
    "    # review_marketplace = row['marketplace']\n",
    "    # customer_id = row['customer_id']\n",
    "    product_id = row['product_id']\n",
    "    # product_parent = row['product_parent']\n",
    "    # product_title = row['product_title']\n",
    "    # product_category = row['product_category']\n",
    "    # date = str(row['review_date'])\n",
    "    # star_rating = row['star_rating']\n",
    "    # url = add_amazonlink(product_id)\n",
    "\n",
    "\n",
    "\n",
    "    doc=nlp(review_body)\n",
    "    #print(\"--- SPACY : Doc loaded ---\")\n",
    "\n",
    "    ## FIRST RULE OF DEPENDANCY PARSE -\n",
    "    ## M - Sentiment modifier || A - Aspect\n",
    "    ## RULE = M is child of A with a relationshio of amod\n",
    "    rule1_pairs = []\n",
    "    rule2_pairs = []\n",
    "    rule3_pairs = []\n",
    "    rule4_pairs = []\n",
    "    rule5_pairs = []\n",
    "    rule6_pairs = []\n",
    "    rule7_pairs = []\n",
    "\n",
    "    for token in doc:\n",
    "        A = \"999999\"\n",
    "        M = \"999999\"\n",
    "        if token.dep_ == \"amod\" and not token.is_stop:\n",
    "            M = token.text\n",
    "            A = token.head.text\n",
    "\n",
    "            # add adverbial modifier of adjective (e.g. 'most comfortable headphones')\n",
    "            M_children = token.children\n",
    "            for child_m in M_children:\n",
    "                if(child_m.dep_ == \"advmod\"):\n",
    "                    M_hash = child_m.text\n",
    "                    M = M_hash + \" \" + M\n",
    "                    break\n",
    "\n",
    "            # negation in adjective, the \"no\" keyword is a 'det' of the noun (e.g. no interesting characters)\n",
    "            A_children = token.head.children\n",
    "            for child_a in A_children:\n",
    "                if(child_a.dep_ == \"det\" and child_a.text == 'no'):\n",
    "                    neg_prefix = 'not'\n",
    "                    M = neg_prefix + \" \" + M\n",
    "                    break\n",
    "\n",
    "        if(A != \"999999\" and M != \"999999\"):\n",
    "            if A in prod_pronouns :\n",
    "                A = \"product\"\n",
    "            dict1 = {\"noun\" : A, \"adj\" : M, \"rule\" : 1, \"polarity\" : sid.polarity_scores(token.text)['compound']}\n",
    "            rule1_pairs.append(dict1)\n",
    "\n",
    "        # print(\"--- SPACY : Rule 1 Done ---\")\n",
    "\n",
    "        # # SECOND RULE OF DEPENDANCY PARSE -\n",
    "        # # M - Sentiment modifier || A - Aspect\n",
    "        # Direct Object - A is a child of something with relationship of nsubj, while\n",
    "        # M is a child of the same something with relationship of dobj\n",
    "        # Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "        children = token.children\n",
    "        A = \"999999\"\n",
    "        M = \"999999\"\n",
    "        add_neg_pfx = False\n",
    "        for child in children :\n",
    "            if(child.dep_ == \"nsubj\" and not child.is_stop):\n",
    "                A = child.text\n",
    "                # check_spelling(child.text)\n",
    "\n",
    "            if((child.dep_ == \"dobj\" and child.pos_ == \"ADJ\") and not child.is_stop):\n",
    "                M = child.text\n",
    "                #check_spelling(child.text)\n",
    "\n",
    "            if(child.dep_ == \"neg\"):\n",
    "                neg_prefix = child.text\n",
    "                add_neg_pfx = True\n",
    "\n",
    "        if (add_neg_pfx and M != \"999999\"):\n",
    "            M = neg_prefix + \" \" + M\n",
    "\n",
    "        if(A != \"999999\" and M != \"999999\"):\n",
    "            if A in prod_pronouns :\n",
    "                A = \"product\"\n",
    "            dict2 = {\"noun\" : A, \"adj\" : M, \"rule\" : 2, \"polarity\" : sid.polarity_scores(token.text)['compound']}\n",
    "            rule2_pairs.append(dict2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # print(\"--- SPACY : Rule 2 Done ---\")\n",
    "\n",
    "        ## THIRD RULE OF DEPENDANCY PARSE -\n",
    "        ## M - Sentiment modifier || A - Aspect\n",
    "        ## Adjectival Complement - A is a child of something with relationship of nsubj, while\n",
    "        ## M is a child of the same something with relationship of acomp\n",
    "        ## Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "        ## \"The sound of the speakers would be better. The sound of the speakers could be better\" - handled using AUX dependency\n",
    "\n",
    "        children = token.children\n",
    "        A = \"999999\"\n",
    "        M = \"999999\"\n",
    "        add_neg_pfx = False\n",
    "        for child in children :\n",
    "            if(child.dep_ == \"nsubj\" and not child.is_stop):\n",
    "                A = child.text\n",
    "                # check_spelling(child.text)\n",
    "\n",
    "            if(child.dep_ == \"acomp\" and not child.is_stop):\n",
    "                M = child.text\n",
    "\n",
    "            # example - 'this could have been better' -> (this, not better)\n",
    "            if(child.dep_ == \"aux\" and child.tag_ == \"MD\"):\n",
    "                neg_prefix = \"not\"\n",
    "                add_neg_pfx = True\n",
    "\n",
    "            if(child.dep_ == \"neg\"):\n",
    "                neg_prefix = child.text\n",
    "                add_neg_pfx = True\n",
    "\n",
    "        if (add_neg_pfx and M != \"999999\"):\n",
    "            M = neg_prefix + \" \" + M\n",
    "                #check_spelling(child.text)\n",
    "\n",
    "        if(A != \"999999\" and M != \"999999\"):\n",
    "            if A in prod_pronouns :\n",
    "                A = \"product\"\n",
    "            dict3 = {\"noun\" : A, \"adj\" : M, \"rule\" : 3, \"polarity\" : sid.polarity_scores(token.text)['compound']}\n",
    "            rule3_pairs.append(dict3)\n",
    "            #rule3_pairs.append((A, M, sid.polarity_scores(M)['compound'],3))\n",
    "    # print(\"--- SPACY : Rule 3 Done ---\")\n",
    "\n",
    "        ## FOURTH RULE OF DEPENDANCY PARSE -\n",
    "        ## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "        #Adverbial modifier to a passive verb - A is a child of something with relationship of nsubjpass, while\n",
    "        # M is a child of the same something with relationship of advmod\n",
    "\n",
    "        #Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "        children = token.children\n",
    "        A = \"999999\"\n",
    "        M = \"999999\"\n",
    "        add_neg_pfx = False\n",
    "        for child in children :\n",
    "            if((child.dep_ == \"nsubjpass\" or child.dep_ == \"nsubj\") and not child.is_stop):\n",
    "                A = child.text\n",
    "                # check_spelling(child.text)\n",
    "\n",
    "            if(child.dep_ == \"advmod\" and not child.is_stop):\n",
    "                M = child.text\n",
    "                M_children = child.children\n",
    "                for child_m in M_children:\n",
    "                    if(child_m.dep_ == \"advmod\"):\n",
    "                        M_hash = child_m.text\n",
    "                        M = M_hash + \" \" + child.text\n",
    "                        break\n",
    "                #check_spelling(child.text)\n",
    "\n",
    "            if(child.dep_ == \"neg\"):\n",
    "                neg_prefix = child.text\n",
    "                add_neg_pfx = True\n",
    "\n",
    "        if (add_neg_pfx and M != \"999999\"):\n",
    "            M = neg_prefix + \" \" + M\n",
    "\n",
    "        if(A != \"999999\" and M != \"999999\"):\n",
    "            if A in prod_pronouns :\n",
    "                A = \"product\"\n",
    "            dict4 = {\"noun\" : A, \"adj\" : M, \"rule\" : 4, \"polarity\" : sid.polarity_scores(token.text)['compound']}\n",
    "            rule4_pairs.append(dict4)\n",
    "            #rule4_pairs.append((A, M,sid.polarity_scores(M)['compound'],4)) # )\n",
    "\n",
    "    # print(\"--- SPACY : Rule 4 Done ---\")\n",
    "\n",
    "\n",
    "        ## FIFTH RULE OF DEPENDANCY PARSE -\n",
    "        ## M - Sentiment modifier || A - Aspect\n",
    "\n",
    "        #Complement of a copular verb - A is a child of M with relationship of nsubj, while\n",
    "        # M has a child with relationship of cop\n",
    "\n",
    "        #Assumption - A verb will have only one NSUBJ and DOBJ\n",
    "\n",
    "        children = token.children\n",
    "        A = \"999999\"\n",
    "        buf_var = \"999999\"\n",
    "        for child in children :\n",
    "            if(child.dep_ == \"nsubj\" and not child.is_stop):\n",
    "                A = child.text\n",
    "                # check_spelling(child.text)\n",
    "\n",
    "            if(child.dep_ == \"cop\" and not child.is_stop):\n",
    "                buf_var = child.text\n",
    "                #check_spelling(child.text)\n",
    "\n",
    "        if(A != \"999999\" and buf_var != \"999999\"):\n",
    "            if A in prod_pronouns :\n",
    "                A = \"product\"\n",
    "            dict5 = {\"noun\" : A, \"adj\" : token.text, \"rule\" : 5, \"polarity\" : sid.polarity_scores(token.text)['compound']}\n",
    "            rule5_pairs.append(dict5)\n",
    "            #rule5_pairs.append((A, token.text,sid.polarity_scores(token.text)['compound'],5))\n",
    "\n",
    "    # print(\"--- SPACY : Rule 5 Done ---\")\n",
    "\n",
    "        ## SIXTH RULE OF DEPENDANCY PARSE -\n",
    "        ## M - Sentiment modifier || A - Aspect\n",
    "        ## Example - \"It ok\", \"ok\" is INTJ (interjections like bravo, great etc)\n",
    "\n",
    "        children = token.children\n",
    "        A = \"999999\"\n",
    "        M = \"999999\"\n",
    "        if(token.pos_ == \"INTJ\" and not token.is_stop):\n",
    "            for child in children :\n",
    "                if(child.dep_ == \"nsubj\" and not child.is_stop):\n",
    "                    A = child.text\n",
    "                    M = token.text\n",
    "                    # check_spelling(child.text)\n",
    "\n",
    "        if(A != \"999999\" and M != \"999999\"):\n",
    "            if A in prod_pronouns :\n",
    "                A = \"product\"\n",
    "            dict6 = {\"noun\" : A, \"adj\" : M, \"rule\" : 6, \"polarity\" : sid.polarity_scores(M)['compound']}\n",
    "            rule6_pairs.append(dict6)\n",
    "\n",
    "            #rule6_pairs.append((A, M,sid.polarity_scores(M)['compound'],6))\n",
    "\n",
    "    # print(\"--- SPACY : Rule 6 Done ---\")\n",
    "\n",
    "    ## SEVENTH RULE OF DEPENDANCY PARSE -\n",
    "    ## M - Sentiment modifier || A - Aspect\n",
    "    ## ATTR - link between a verb like 'be/seem/appear' and its complement\n",
    "    ## Example: 'this is garbage' -> (this, garbage)\n",
    "\n",
    "        children = token.children\n",
    "        A = \"999999\"\n",
    "        M = \"999999\"\n",
    "        add_neg_pfx = False\n",
    "        for child in children :\n",
    "            if(child.dep_ == \"nsubj\" and not child.is_stop):\n",
    "                A = child.text\n",
    "                # check_spelling(child.text)\n",
    "\n",
    "            if((child.dep_ == \"attr\") and not child.is_stop):\n",
    "                M = child.text\n",
    "                #check_spelling(child.text)\n",
    "\n",
    "            if(child.dep_ == \"neg\"):\n",
    "                neg_prefix = child.text\n",
    "                add_neg_pfx = True\n",
    "\n",
    "        if (add_neg_pfx and M != \"999999\"):\n",
    "            M = neg_prefix + \" \" + M\n",
    "\n",
    "        if(A != \"999999\" and M != \"999999\"):\n",
    "            if A in prod_pronouns :\n",
    "                A = \"product\"\n",
    "            dict7 = {\"noun\" : A, \"adj\" : M, \"rule\" : 7, \"polarity\" : sid.polarity_scores(M)['compound']}\n",
    "            rule7_pairs.append(dict7)\n",
    "            #rule7_pairs.append((A, M,sid.polarity_scores(M)['compound'],7))\n",
    "\n",
    "\n",
    "\n",
    "    #print(\"--- SPACY : Rules Done ---\")\n",
    "\n",
    "\n",
    "    aspects = []\n",
    "\n",
    "    aspects = rule1_pairs + rule2_pairs + rule3_pairs +rule4_pairs +rule5_pairs + rule6_pairs + rule7_pairs\n",
    "\n",
    "    # replace all instances of \"it\", \"this\" and \"they\" with \"product\"\n",
    "    #aspects = [(A,M,P,r) if A not in prod_pronouns else (\"product\",M,P,r) for A,M,P,r in aspects ]\n",
    "\n",
    "    # dic = {\"review_id\" : review_id , \"aspect_pairs\" : aspects, \"review_marketplace\" : review_marketplace\n",
    "    # , \"customer_id\" : customer_id, \"product_id\" : product_id, \"product_parent\" : product_parent,\n",
    "    # \"product_title\" : product_title, \"product_category\" : product_category, \"date\" : date, \"star_rating\" : star_rating, \"url\" : url}\n",
    "\n",
    "    dic = {\"product_id\" : product_id ,\"review_id\" : review_id , \"aspect_pairs\" : aspects}\n",
    "    return dic\n",
    "\n",
    "\n",
    "def extract_aspects(reviews,nlp,sid):\n",
    "\n",
    "    #reviews = df[['review_id', 'review_body']]\n",
    "    # nlp = init_spacy()\n",
    "    # sid = init_nltk()\n",
    "\n",
    "    print(\"Entering Apply function!\")\n",
    "    aspect_list = reviews.apply(lambda row: apply_extraction(row,nlp,sid), axis=1) #going through all the rows in the dataframe\n",
    "    return aspect_list\n",
    "\n",
    "\n",
    "def aspect_extraction(nlp,sid,arg):\n",
    "    usecols =  ['review_id','review_body','product_id']\n",
    "\n",
    "    # filepath = BASE_PATH + \"/data/raw/amazon_reviews_us_Electronics_v1_00.tsv\"\n",
    "    # reviews =  fetch_reviews(filepath,usecols)\n",
    "\n",
    "    # UNCOMMENT THIS WHEN RUNNING ON AWS\n",
    "    if arg == 0 :\n",
    "        print(\"$$$$$$ Running for the one whole file $$$$$$\")\n",
    "\n",
    "        s3_filename = \"amazon_reviews_us_Electronics_v1_00.tsv.gz\"\n",
    "        raw_data = fetch_s3(s3_filename, usecols)\n",
    "\n",
    "        # reviews = clean_data.clean_data(reviews)\n",
    "        # aspect_list = extract_aspects(reviews,nlp,sid)\n",
    "        print(\"Working on Chunks!!!\")\n",
    "        chunk_count = 0\n",
    "        #reviews = pd.DataFrame()\n",
    "        for reviews in raw_data:\n",
    "            chunk_count = chunk_count + 1\n",
    "            reviews = clean_data.clean_data(reviews)\n",
    "            time_start = time()\n",
    "            aspect_list = extract_aspects(reviews,nlp,sid)\n",
    "            time_end = time()\n",
    "            print(\"Time for aspect extraction: {0:.2}s\".format(time_end-time_start))\n",
    "            print(f'Updating chunk results : {chunk_count}')\n",
    "            time_start_1 = time()\n",
    "            print(\"Appending to JSON FIle\")\n",
    "            aspect_list = list(aspect_list)\n",
    "            with open('data/interim/reviews_aspect_raw.json', 'a') as outfile:\n",
    "                json.dump(aspect_list, outfile)\n",
    "            time_end_1 = time()\n",
    "            print(\"Time for Writing: {0:.2}s\".format(time_end_1-time_start_1))\n",
    "\n",
    "            print(\"Finished writing results to JSON!!\")\n",
    "            print(\"----------------***----------------\")\n",
    "\n",
    "    else :\n",
    "        print(\"&&&&& Running for the toy file &&&&&\")\n",
    "        reviews = pd.read_table(\"data/raw/toy.tsv\",error_bad_lines=False, usecols= usecols)\n",
    "        reviews = clean_data.clean_data(reviews)\n",
    "        aspect_list = extract_aspects(reviews,nlp,sid)\n",
    "        aspect_list = list(aspect_list)\n",
    "        with open('data/interim/reviews_aspect_raw.json', 'w') as outfile:\n",
    "            json.dump(aspect_list, outfile)\n",
    "        #reviews = pd.concat([reviews,chunk])\n",
    "\n",
    "    #print(f'Shape of the merged file:{reviews.shape}')\n",
    "\n",
    "\n",
    "\n",
    "    return 1\n",
    "\n",
    "\n",
    "def add_amazonlink(product_id):\n",
    "    AMAZON_BASE_URL = \"http://amazon.com/dp/\"\n",
    "    url = AMAZON_BASE_URL + str(product_id)\n",
    "    #product_url = {\"product_id\" : product_id, \"url\" : url}\n",
    "    return url\n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    # nlp = init_spacy()\n",
    "    a = aspect_extraction(nlp,sid)\n",
    "\n",
    "    # USE THIS IF YOU WANT TO SEE THE ASPECTS IN A FILE\n",
    "    # with open('your_file.txt', 'w') as f:\n",
    "    #     for item in a:\n",
    "    #         f.write(\"%s\\n\" % item)\n"
   ]
  }
 ],
 "metadata": {
  "creator": "admin",
  "customFields": {},
  "kernelspec": {
   "display_name": "Python (env python36)",
   "language": "python",
   "name": "py-dku-venv-python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "tags": []
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
